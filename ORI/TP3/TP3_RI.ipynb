{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP3-RI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#TP3"
      ],
      "metadata": {
        "id": "tQjDUSH1Hxoj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando as bibliotecas"
      ],
      "metadata": {
        "id": "Bo87ySnHHS5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpTZ4GX5Hbqf",
        "outputId": "280fb5b0-3491-4ba9-e943-39adefe0984d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7yCP_7OLUhB",
        "outputId": "df846487-1123-4ecf-ebe1-ecfea30b495e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parte 1"
      ],
      "metadata": {
        "id": "okbp07V0H8ew"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOezR6D9HIg3",
        "outputId": "daaf4541-099b-4caf-b450-1b02296ca8da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulario: ['am', 'be', 'da', 'do', 'i', 'is', 'it', 'let', 'not', 'or', 'therefore', 'think', 'to', 'what']\n",
            "\n",
            "Documento: ['to', 'do', 'is', 'to', 'be', 'to', 'be', 'is', 'to', 'do']\n",
            "Bag of Words: [0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 4, 0]\n",
            "TF: [0, 2.0, 0, 2.0, 0, 2.0, 0, 0, 0, 0, 0, 0, 3.0, 0]\n",
            "\n",
            "Documento: ['to', 'be', 'or', 'not', 'to', 'be', 'i', 'am', 'what', 'i', 'am']\n",
            "Bag of Words: [2, 2, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 2, 1]\n",
            "TF: [2.0, 2.0, 0, 0, 2.0, 0, 0, 0, 1.0, 1.0, 0, 0, 2.0, 1.0]\n",
            "\n",
            "Documento: ['i', 'think', 'therefore', 'i', 'am', 'do', 'be', 'do', 'be', 'do']\n",
            "Bag of Words: [1, 2, 0, 3, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0]\n",
            "TF: [1.0, 2.0, 0, 2.585, 2.0, 0, 0, 0, 0, 0, 1.0, 1.0, 0, 0]\n",
            "\n",
            "Documento: ['do', 'do', 'do', 'da', 'da', 'da', 'let', 'it', 'be', 'let', 'it', 'be']\n",
            "Bag of Words: [0, 2, 3, 3, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0]\n",
            "TF: [0, 2.0, 2.585, 2.585, 0, 0, 2.0, 2.0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "IDF: [1.0, 0.0, 2.0, 0.415, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0]\n",
            "\n",
            "TF-IDF\n",
            "d1.txt: [0.0, 0.0, 0.0, 0.83, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0]\n",
            "d2.txt: [2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0, 2.0]\n",
            "d3.txt: [1.0, 0.0, 0.0, 1.073, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0]\n",
            "d4.txt: [0.0, 0.0, 5.17, 1.073, 0.0, 0.0, 4.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "\n",
            "Digite a consulta ('!' para terminar): to do\n",
            "TF-IDF Consulta: [0.0, 0.0, 0.0, 0.415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
            "\n",
            "Grau de Similaridade\n",
            "d1.txt: 0.6094617632953867\n",
            "d2.txt: 0.37706731211797234\n",
            "d3.txt: 0.10933109935552829\n",
            "d4.txt: 0.053149673715062226\n",
            "\n",
            "Documento mais Similar: d1.txt\n",
            "To do is to be.\n",
            "To be is to do.\n",
            "\n",
            "Digite a consulta ('!' para terminar): !\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "import unidecode\n",
        "import math\n",
        "import numpy\n",
        "import re\n",
        "\n",
        "\n",
        "def abreArquivo(nomeArquivo):\n",
        "  fp = open(nomeArquivo, 'r')\n",
        "  texto = fp.read()\n",
        "  return texto\n",
        "\n",
        "#abre o arquivo, faz o unidecode, remove pontuação, separa os termos, ordena os termos, remove duplicatas e \n",
        "#retorna a lista de termos\n",
        "def separaArquivo(nomeArquivo):\n",
        "  texto = abreArquivo(nomeArquivo)\n",
        "  termos = separaString(texto)\n",
        "  termos.sort()\n",
        "  termos = list(dict.fromkeys(termos))\n",
        "\n",
        "  return termos\n",
        "\n",
        "#abre o arquivo, faz o unidecode, remove pontuação, separa os termos, ordena os termos, mas não remove duplicatas\n",
        "def listaArquivo(nomeArquivo):\n",
        "  texto = abreArquivo(nomeArquivo)\n",
        "  termos = separaString(texto)\n",
        "\n",
        "  return termos\n",
        "\n",
        "def separaString(texto):\n",
        "  texto = unidecode.unidecode(texto)\n",
        "  pontuacao = string.punctuation\n",
        "  for i in pontuacao:\n",
        "    texto = texto.replace(i,\"\")\n",
        "  \n",
        "  texto = re.sub(r'\\d+', '', texto)\n",
        "  termos = texto.lower().split()\n",
        "\n",
        "  return termos\n",
        "\n",
        "def normalizaConsulta(vocabulario, consulta):\n",
        "  termosConsulta = separaString(consulta)\n",
        "  termos = []\n",
        "  for i in termosConsulta:\n",
        "    if i in vocabulario:\n",
        "      termos.append(i)\n",
        "\n",
        "  return termos\n",
        "  \n",
        "def comparaTermos(vocabulario, documento):\n",
        "  bagOfWords = []\n",
        "  for i in vocabulario:\n",
        "    if i in documento:\n",
        "      bagOfWords.append(1)\n",
        "    else:\n",
        "      bagOfWords.append(0)\n",
        "\n",
        "  return bagOfWords\n",
        "\n",
        "def frequenciaTermos(vocabulario, documento):\n",
        "  bagOfWords = []\n",
        "  for i in vocabulario:\n",
        "    for j in documento:\n",
        "      if j in vocabulario:\n",
        "        contador = documento.count(i)\n",
        "        bagOfWords.append(contador)\n",
        "        break\n",
        "      else:\n",
        "        bagOfWords.append(0)\n",
        "        break\n",
        "\n",
        "  return bagOfWords\n",
        "\n",
        "def calculaTF(bagOfWords):\n",
        "  tf = []\n",
        "  log = 0\n",
        "  for i in bagOfWords:\n",
        "    num = int(i)\n",
        "    if num!=0:\n",
        "      log = math.log(num, 2)\n",
        "      tf.append(round(1+log, 3))\n",
        "    else:\n",
        "      tf.append(0)\n",
        "\n",
        "  return tf\n",
        "\n",
        "def calculaIDF(lista):\n",
        "  vocabulario = geraVocabulario(lista)\n",
        "  idf = []\n",
        "  for i in vocabulario:\n",
        "      contador = 0\n",
        "      for j in lista:\n",
        "          documento = separaArquivo(j)\n",
        "          if i in documento:\n",
        "              contador = contador + 1\n",
        "      idf.append(contador)\n",
        "  idf = [round(math.log(len(lista)/i, 2),3) for i in idf]\n",
        "\n",
        "  return idf\n",
        "\n",
        "def calculaTFIDFLista(vocabulario, lista):\n",
        "  idf = calculaIDF(lista)\n",
        "  listaTFIDF = []\n",
        "  for i in lista:\n",
        "    tfidf = []\n",
        "    documento = listaArquivo(i)\n",
        "    bagOfWords = frequenciaTermos(vocabulario, documento)\n",
        "    tf = calculaTF(bagOfWords)\n",
        "    tfidf = [round(tf[j]*idf[j], 3) for j in range(len(tf))]\n",
        "    listaTFIDF.append(tfidf)\n",
        "  \n",
        "  return listaTFIDF\n",
        "\n",
        "def calculaTFIDFConsulta(vocabulario, lista, consulta):\n",
        "  termosConsulta = normalizaConsulta(vocabulario, consulta)\n",
        "  bag = frequenciaTermos(vocabulario, termosConsulta)\n",
        "  idf = calculaIDF(lista)\n",
        "  tf = calculaTF(bag)\n",
        "  tfidf = [round(tf[j]*idf[j], 3) for j in range(len(tf))]\n",
        "  print(f'TF-IDF Consulta: {tfidf}')\n",
        "\n",
        "  return tfidf\n",
        "  \n",
        "\n",
        "def mostraDadosListaArquivos(vocabulario, lista):\n",
        "  for i in lista:\n",
        "    bagOfWords = []\n",
        "    documento = listaArquivo(i)\n",
        "    print(f'\\nDocumento: {documento}')\n",
        "    bagOfWords = frequenciaTermos(vocabulario, documento)\n",
        "    print(f'Bag of Words: {bagOfWords}')\n",
        "    tf = calculaTF(bagOfWords)\n",
        "    print(f'TF: {tf}')\n",
        "\n",
        "\n",
        "def geraVocabulario(lista):\n",
        "    vocabulario = []\n",
        "    for i in lista:\n",
        "        documento = separaArquivo(i)\n",
        "        vocabulario = vocabulario + documento\n",
        "    vocabulario = list(dict.fromkeys(vocabulario))\n",
        "    vocabulario.sort()\n",
        "\n",
        "    return vocabulario\n",
        "\n",
        "def escreveVocabulario(lista):\n",
        "    vocabulario = geraVocabulario(lista)\n",
        "    fp = open('vocabulario.txt', 'w')\n",
        "    for i in vocabulario:\n",
        "        fp.write(i + '\\n')\n",
        "\n",
        "def calculaSimilaridade(vetorA, vetorB):\n",
        "  produtoInterno = 0\n",
        "  if len(vetorA)>0 and len(vetorB)>0: \n",
        "    for i in range (len(vetorA)):\n",
        "      temp = vetorA[i]*vetorB[i]\n",
        "      produtoInterno = produtoInterno + temp\n",
        "\n",
        "  normaVetorA = numpy.linalg.norm(vetorA)\n",
        "  normaVetorB = numpy.linalg.norm(vetorB)\n",
        "  #print(f'Norma A: {normaVetorA}')\n",
        "  #print(f'Norma B: {normaVetorB}')\n",
        "  produtoNorma = normaVetorA*normaVetorB\n",
        "  if produtoNorma!=0:\n",
        "    similaridade = produtoInterno/produtoNorma\n",
        "  else:\n",
        "    similaridade = 0\n",
        "\n",
        "  return similaridade\n",
        "\n",
        "def calculaSimilaridadeLista(tfidf, vetorConsulta):\n",
        "  vetorSimilaridades = []\n",
        "  for i in range(len(tfidf)):\n",
        "    vetorSimilaridades.append(calculaSimilaridade(tfidf[i], vetorConsulta))\n",
        "\n",
        "  return vetorSimilaridades\n",
        "\n",
        "def mostraVetor(vetor):\n",
        "  print('\\n'.join('{}: {}'.format(*k) for k in enumerate(vetor, 1)))\n",
        "\n",
        "def mostraNomeVetor(vetor, lista):\n",
        "  for i in range(len(vetor)):\n",
        "    print(f'{lista[i]}: {vetor[i]}')\n",
        "\n",
        "def mostraDocSimilar(vetorSimilaridade, lista):\n",
        "  maiorSim = max(vetorSimilaridade)\n",
        "\n",
        "  if maiorSim == 0:\n",
        "    print(f'\\nNao existe documento similar na colecao')\n",
        "    return\n",
        "\n",
        "  posDoc = vetorSimilaridade.index(maiorSim)\n",
        "  print(f'\\nDocumento mais Similar: {lista[posDoc]}')\n",
        "  print(abreArquivo(lista[posDoc]))\n",
        "\n",
        "def inputCalculaConsulta(vocabulario, lista, tfidf):\n",
        "  while(1):\n",
        "    consulta = input(\"\\nDigite a consulta ('!' para terminar): \")\n",
        "    if consulta == '!':\n",
        "      break\n",
        "\n",
        "    vetorConsulta = calculaTFIDFConsulta(vocabulario, lista, consulta)\n",
        "\n",
        "    vetorSimilaridade = calculaSimilaridadeLista(tfidf, vetorConsulta)\n",
        "\n",
        "    print('\\nGrau de Similaridade')\n",
        "    mostraNomeVetor(vetorSimilaridade, lista)\n",
        "\n",
        "    mostraDocSimilar(vetorSimilaridade, lista)\n",
        "\n",
        "  \n",
        "listaDoc = ['d1.txt', 'd2.txt', 'd3.txt', 'd4.txt']\n",
        "\n",
        "vocabulario = geraVocabulario(listaDoc)\n",
        "print(f'Vocabulario: {vocabulario}')\n",
        "mostraDadosListaArquivos(vocabulario, listaDoc)\n",
        "\n",
        "idf = calculaIDF(listaDoc)\n",
        "print(f'\\nIDF: {idf}\\n')\n",
        "\n",
        "tfidf = calculaTFIDFLista(vocabulario, listaDoc)\n",
        "\n",
        "print('TF-IDF')\n",
        "mostraNomeVetor(tfidf, listaDoc)\n",
        "\n",
        "inputCalculaConsulta(vocabulario, listaDoc, tfidf)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parte 2"
      ],
      "metadata": {
        "id": "XSw2LXnqSYv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import unidecode\n",
        "import math\n",
        "import numpy\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "\n",
        "def abreArquivo(nomeArquivo):\n",
        "  fp = open(nomeArquivo, 'r')\n",
        "  texto = fp.read()\n",
        "  return texto\n",
        "\n",
        "#abre o arquivo, faz o unidecode, remove pontuação, separa os termos, ordena os termos, remove duplicatas e \n",
        "#retorna a lista de termos\n",
        "def separaArquivo(nomeArquivo):\n",
        "  texto = abreArquivo(nomeArquivo)\n",
        "  termos = separaString(texto)\n",
        "  termos.sort()\n",
        "  termos = list(dict.fromkeys(termos))\n",
        "\n",
        "  return termos\n",
        "\n",
        "#abre o arquivo, faz o unidecode, remove pontuação, separa os termos, ordena os termos, mas não remove duplicatas\n",
        "def listaArquivo(nomeArquivo):\n",
        "  texto = abreArquivo(nomeArquivo)\n",
        "  termos = separaString(texto)\n",
        "\n",
        "  return termos\n",
        "\n",
        "#stopwords tratadas\n",
        "def getStopwords():\n",
        "  nltk.download('stopwords')\n",
        "  stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "  stopwordsUni = []\n",
        "  for i in stopwords:\n",
        "    stopwordsUni.append(unidecode.unidecode(i))\n",
        "  stopwordsUni = list(dict.fromkeys(stopwordsUni))\n",
        "\n",
        "  return stopwordsUni\n",
        "\n",
        "stopwords = getStopwords()\n",
        "def separaString(texto):\n",
        "  texto = unidecode.unidecode(texto)\n",
        "  pontuacao = string.punctuation\n",
        "  for i in pontuacao:\n",
        "    texto = texto.replace(i,\"\")\n",
        "  \n",
        "  texto = re.sub(r'\\d+', '', texto)\n",
        "  termos = texto.lower().split()\n",
        "\n",
        "  for i in stopwords:\n",
        "    while i in termos:\n",
        "      termos.remove(i)\n",
        "\n",
        "  return termos\n",
        "\n",
        "def geraVocabulario(lista):\n",
        "    vocabulario = []\n",
        "    for i in lista:\n",
        "        documento = separaArquivo(i)\n",
        "        vocabulario = vocabulario + documento\n",
        "    vocabulario = list(dict.fromkeys(vocabulario))\n",
        "    vocabulario.sort()\n",
        "\n",
        "    return vocabulario\n",
        "\n",
        "def escreveVocabulario(lista):\n",
        "    vocabulario = geraVocabulario(lista)\n",
        "    fp = open('vocabulario.txt', 'w')\n",
        "    for i in vocabulario:\n",
        "        fp.write(i + '\\n')\n",
        "\n",
        "#teste com alguns hinos\n",
        "listaDoc = ['hinoAtleticoMG.txt', 'hinoCorinthians.txt', 'hinoFlamengo.txt', 'hinoFluminense.txt',\n",
        "            'hinoInternacional.txt', 'hinoPalmeiras.txt', 'hinoSantos.txt', 'hinoSaoPaulo.txt']\n",
        "\n",
        "\n",
        "vocabulario = geraVocabulario(listaDoc)\n",
        "\n",
        "print(f'StopWords: {stopwords}')\n",
        "print(f'\\nVocabulario: {vocabulario}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxPIboLzSaJV",
        "outputId": "dd9d4f2b-490b-45e7-a0bb-02b3e9579f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StopWords: ['de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para', 'com', 'nao', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'ja', 'eu', 'tambem', 'so', 'pelo', 'pela', 'ate', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'voce', 'essa', 'num', 'nem', 'suas', 'meu', 'minha', 'numa', 'pelos', 'elas', 'qual', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'voces', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'estamos', 'estao', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estavamos', 'estavam', 'estivera', 'estiveramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivessemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'ha', 'havemos', 'hao', 'houve', 'houvemos', 'houveram', 'houvera', 'houveramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvessemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houveremos', 'houverao', 'houveria', 'houveriamos', 'houveriam', 'sou', 'somos', 'sao', 'era', 'eramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'foramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fossemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'sera', 'seremos', 'serao', 'seria', 'seriamos', 'seriam', 'tenho', 'tem', 'temos', 'tinha', 'tinhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tiveramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivessemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'tera', 'teremos', 'terao', 'teria', 'teriamos', 'teriam']\n",
            "\n",
            "Vocabulario: ['absoluto', 'agora', 'aguarda', 'ai', 'alcanca', 'alcapao', 'alegres', 'alegria', 'altaneiro', 'alvinegro', 'alvirubro', 'alviverde', 'amado', 'amam', 'amanha', 'amor', 'ano', 'anos', 'ardor', 'arrebata', 'ases', 'astros', 'atacante', 'atletico', 'azul', 'bandeira', 'bem', 'bola', 'brasil', 'brasileiro', 'brasileiros', 'bretao', 'brilhar', 'campeao', 'campeoes', 'canta', 'celeiro', 'cenario', 'ceu', 'cintilam', 'clube', 'colorado', 'consagrado', 'coracao', 'coracoes', 'cores', 'corinthians', 'correm', 'cotado', 'defesa', 'dentre', 'dentro', 'desgosto', 'desportistas', 'desporto', 'deste', 'dignamente', 'disciplina', 'distantes', 'diz', 'domina', 'dureza', 'emocao', 'emocoes', 'encarnado', 'es', 'espera', 'esperanca', 'esporte', 'esportivo', 'eternamente', 'exaltar', 'faltasse', 'fascina', 'fato', 'faz', 'feitos', 'festas', 'fibra', 'figuras', 'flaflu', 'flamengo', 'fluminense', 'forte', 'frente', 'galo', 'gelo', 'gloria', 'glorias', 'glorioso', 'gramado', 'gramados', 'grande', 'grandes', 'guias', 'honramos', 'ideal', 'imortal', 'imponente', 'inteiro', 'internacional', 'jesus', 'jogamos', 'jogar', 'jogue', 'lealdade', 'leao', 'levar', 'levas', 'libra', 'licao', 'linha', 'luta', 'lutar', 'luz', 'maior', 'maltrata', 'mar', 'mata', 'mil', 'minas', 'mineiro', 'morrer', 'mostrar', 'motivo', 'muita', 'mundial', 'mundo', 'nacional', 'ninguem', 'nome', 'novo', 'oh', 'orgulha', 'orgulho', 'ostentando', 'ostentas', 'padrao', 'palmeiras', 'partida', 'passa', 'passado', 'paulista', 'paulo', 'pavilhao', 'paz', 'pesou', 'plagas', 'pois', 'povo', 'pra', 'praiano', 'prazer', 'prelio', 'presente', 'primeiro', 'primeiros', 'profundo', 'querida', 'querido', 'raca', 'radioso', 'regata', 'relevantes', 'retumbante', 'rio', 'sabe', 'salve', 'sangue', 'santos', 'segue', 'sempre', 'senda', 'ser', 'sul', 'surge', 'tantas', 'tarda', 'tens', 'ternamente', 'terra', 'time', 'toda', 'torcida', 'tradicao', 'tradicoes', 'traduzem', 'transformando', 'trazendo', 'tres', 'tricampeao', 'tricolor', 'tudo', 'unido', 'varonil', 'velo', 'vem', 'vence', 'vencer', 'vencida', 'verde', 'vez', 'vezes', 'vibra', 'vibramos', 'vibrar', 'vigor', 'vingador', 'vitorias', 'vives', 'vivo']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parte 3 sem steamming"
      ],
      "metadata": {
        "id": "Nar3aSSfVE-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import unidecode\n",
        "import math\n",
        "import numpy\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "\n",
        "def abreArquivo(nomeArquivo):\n",
        "  fp = open(nomeArquivo, 'r')\n",
        "  texto = fp.read()\n",
        "  return texto\n",
        "\n",
        "#abre o arquivo, faz o unidecode, remove pontuação, separa os termos, ordena os termos, remove duplicatas e \n",
        "#retorna a lista de termos\n",
        "def separaArquivo(nomeArquivo):\n",
        "  texto = abreArquivo(nomeArquivo)\n",
        "  termos = separaString(texto)\n",
        "  termos.sort()\n",
        "  termos = list(dict.fromkeys(termos))\n",
        "\n",
        "  return termos\n",
        "\n",
        "#abre o arquivo, faz o unidecode, remove pontuação, separa os termos, ordena os termos, mas não remove duplicatas\n",
        "def listaArquivo(nomeArquivo):\n",
        "  texto = abreArquivo(nomeArquivo)\n",
        "  termos = separaString(texto)\n",
        "\n",
        "  return termos\n",
        "\n",
        "#stopwords tratadas\n",
        "def getStopwords():\n",
        "  nltk.download('stopwords')\n",
        "  stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "  stopwordsUni = []\n",
        "  for i in stopwords:\n",
        "    stopwordsUni.append(unidecode.unidecode(i))\n",
        "  stopwordsUni = list(dict.fromkeys(stopwordsUni))\n",
        "\n",
        "  return stopwordsUni\n",
        "\n",
        "stopwords = getStopwords()\n",
        "def separaString(texto):\n",
        "  texto = unidecode.unidecode(texto)\n",
        "  pontuacao = string.punctuation\n",
        "  for i in pontuacao:\n",
        "    texto = texto.replace(i,\"\")\n",
        "  \n",
        "  texto = re.sub(r'\\d+', '', texto)\n",
        "  termos = texto.lower().split()\n",
        "\n",
        "  for i in stopwords:\n",
        "    while i in termos:\n",
        "      termos.remove(i)\n",
        "\n",
        "  return termos\n",
        "\n",
        "def normalizaConsulta(vocabulario, consulta):\n",
        "  termosConsulta = separaString(consulta)\n",
        "  termos = []\n",
        "  for i in termosConsulta:\n",
        "    if i in vocabulario:\n",
        "      termos.append(i)\n",
        "\n",
        "  return termos\n",
        "\n",
        "  \n",
        "def comparaTermos(vocabulario, documento):\n",
        "  bagOfWords = []\n",
        "  for i in vocabulario:\n",
        "    if i in documento:\n",
        "      bagOfWords.append(1)\n",
        "    else:\n",
        "      bagOfWords.append(0)\n",
        "\n",
        "  return bagOfWords\n",
        "\n",
        "def frequenciaTermos(vocabulario, documento):\n",
        "  bagOfWords = []\n",
        "  for i in vocabulario:\n",
        "    for j in documento:\n",
        "      if j in vocabulario:\n",
        "        contador = documento.count(i)\n",
        "        bagOfWords.append(contador)\n",
        "        break\n",
        "      else:\n",
        "        bagOfWords.append(0)\n",
        "        break\n",
        "\n",
        "  return bagOfWords\n",
        "\n",
        "def calculaTF(bagOfWords):\n",
        "  tf = []\n",
        "  log = 0\n",
        "  for i in bagOfWords:\n",
        "    num = int(i)\n",
        "    if num!=0:\n",
        "      log = math.log(num, 2)\n",
        "      tf.append(round(1+log, 3))\n",
        "    else:\n",
        "      tf.append(0)\n",
        "\n",
        "  return tf\n",
        "\n",
        "def calculaIDF(lista):\n",
        "  vocabulario = geraVocabulario(lista)\n",
        "  idf = []\n",
        "  for i in vocabulario:\n",
        "      contador = 0\n",
        "      for j in lista:\n",
        "          documento = separaArquivo(j)\n",
        "          if i in documento:\n",
        "              contador = contador + 1\n",
        "      idf.append(contador)\n",
        "  idf = [round(math.log(len(lista)/i, 2),3) for i in idf]\n",
        "\n",
        "  return idf\n",
        "\n",
        "def calculaTFIDFLista(vocabulario, lista):\n",
        "  idf = calculaIDF(lista)\n",
        "  listaTFIDF = []\n",
        "  for i in lista:\n",
        "    tfidf = []\n",
        "    documento = listaArquivo(i)\n",
        "    bagOfWords = frequenciaTermos(vocabulario, documento)\n",
        "    tf = calculaTF(bagOfWords)\n",
        "    tfidf = [round(tf[j]*idf[j], 3) for j in range(len(tf))]\n",
        "    listaTFIDF.append(tfidf)\n",
        "  \n",
        "  return listaTFIDF\n",
        "\n",
        "def calculaTFIDFConsulta(vocabulario, lista, consulta):\n",
        "  termosConsulta = normalizaConsulta(vocabulario, consulta)\n",
        "  bag = frequenciaTermos(vocabulario, termosConsulta)\n",
        "  idf = calculaIDF(lista)\n",
        "  tf = calculaTF(bag)\n",
        "  tfidf = [round(tf[j]*idf[j], 3) for j in range(len(tf))]\n",
        "\n",
        "  return tfidf\n",
        "  \n",
        "\n",
        "def mostraDadosListaArquivos(vocabulario, lista):\n",
        "  for i in lista:\n",
        "    bagOfWords = []\n",
        "    documento = listaArquivo(i)\n",
        "    print(f'\\nDocumento: {documento}')\n",
        "    bagOfWords = frequenciaTermos(vocabulario, documento)\n",
        "    print(f'Bag of Words: {bagOfWords}')\n",
        "    tf = calculaTF(bagOfWords)\n",
        "    print(f'TF: {tf}')\n",
        "\n",
        "\n",
        "def geraVocabulario(lista):\n",
        "    vocabulario = []\n",
        "    for i in lista:\n",
        "        documento = separaArquivo(i)\n",
        "        vocabulario = vocabulario + documento\n",
        "    vocabulario = list(dict.fromkeys(vocabulario))\n",
        "    vocabulario.sort()\n",
        "\n",
        "    return vocabulario\n",
        "\n",
        "def escreveVocabulario(lista):\n",
        "    vocabulario = geraVocabulario(lista)\n",
        "    fp = open('vocabulario.txt', 'w')\n",
        "    for i in vocabulario:\n",
        "        fp.write(i + '\\n')\n",
        "\n",
        "def calculaSimilaridade(vetorA, vetorB):\n",
        "  produtoInterno = 0\n",
        "  for i in range (len(vetorA)):\n",
        "    temp = vetorA[i]*vetorB[i]\n",
        "    produtoInterno = produtoInterno + temp\n",
        "\n",
        "  normaVetorA = numpy.linalg.norm(vetorA)\n",
        "  normaVetorB = numpy.linalg.norm(vetorB)\n",
        "  produtoNorma = normaVetorA*normaVetorB\n",
        "  if produtoNorma!=0:\n",
        "    similaridade = produtoInterno/produtoNorma\n",
        "  else:\n",
        "    similaridade = 0\n",
        "\n",
        "  return similaridade\n",
        "\n",
        "def calculaSimilaridadeLista(tfidf, vetorConsulta):\n",
        "  vetorSimilaridades = []\n",
        "  for i in range(len(tfidf)):\n",
        "    vetorSimilaridades.append(calculaSimilaridade(tfidf[i], vetorConsulta))\n",
        "\n",
        "  return vetorSimilaridades\n",
        "\n",
        "def mostraVetor(vetor):\n",
        "  print('\\n'.join('{}: {}'.format(*k) for k in enumerate(vetor, 1)))\n",
        "\n",
        "def mostraNomeVetor(vetor, lista):\n",
        "  for i in range(len(vetor)):\n",
        "    print(f'{lista[i]}: {vetor[i]}')\n",
        "\n",
        "def mostraDocSimilar(vetorSimilaridade, lista):\n",
        "  maiorSim = max(vetorSimilaridade)\n",
        "\n",
        "  if maiorSim == 0:\n",
        "    print(f'\\nNao existe documento similar na colecao')\n",
        "    return\n",
        "\n",
        "  posDoc = vetorSimilaridade.index(maiorSim)\n",
        "  print(f'\\nDocumento mais Similar: {lista[posDoc]}')\n",
        "  print(abreArquivo(lista[posDoc]))\n",
        "\n",
        "def inputCalculaConsulta(vocabulario, lista, tfidf):\n",
        "  while(1):\n",
        "    consulta = input(\"\\nDigite a consulta ('!' para terminar): \")\n",
        "    if consulta == '!':\n",
        "      break\n",
        "\n",
        "    vetorConsulta = calculaTFIDFConsulta(vocabulario, lista, consulta)\n",
        "\n",
        "    vetorSimilaridade = calculaSimilaridadeLista(tfidf, vetorConsulta)\n",
        "\n",
        "    print('\\nGrau de Similaridade')\n",
        "    mostraNomeVetor(vetorSimilaridade, lista)\n",
        "\n",
        "    mostraDocSimilar(vetorSimilaridade, lista)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "listaDoc = [ 'hinoAmericaMG.txt', 'hinoAthletico.txt', 'hinoAtleticoGO.txt', 'hinoAtleticoMG.txt', 'hinoAvai.txt',\n",
        "          'hinoBotafogo.txt', 'hinoBragantino.txt', 'hinoCeara.txt', 'hinoCorinthians.txt', 'hinoCoritiba.txt',\n",
        "          'hinoCuiaba.txt', 'hinoFlamengo.txt', 'hinoFluminense.txt', 'hinoFortaleza.txt', 'hinoGoias.txt',\n",
        "          'hinoInternacional.txt', 'hinoJuventude.txt','hinoPalmeiras.txt', 'hinoSantos.txt', 'hinoSaoPaulo.txt'] \n",
        "vocabulario = geraVocabulario(listaDoc)\n",
        "\n",
        "tfidf = calculaTFIDFLista(vocabulario, listaDoc)\n",
        "inputCalculaConsulta(vocabulario, listaDoc, tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLLvV1XZVG29",
        "outputId": "816708d5-6a8b-437c-ab2d-42d6870b888a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Digite a consulta ('!' para terminar): salve o tricolor  paulista amado clube brasileiro\n",
            "\n",
            "Grau de Similaridade\n",
            "hinoAmericaMG.txt: 0.0\n",
            "hinoAthletico.txt: 0.0\n",
            "hinoAtleticoGO.txt: 0.0\n",
            "hinoAtleticoMG.txt: 0.018898852709640757\n",
            "hinoAvai.txt: 0.0\n",
            "hinoBotafogo.txt: 0.0\n",
            "hinoBragantino.txt: 0.0\n",
            "hinoCeara.txt: 0.0\n",
            "hinoCorinthians.txt: 0.10682467878266919\n",
            "hinoCoritiba.txt: 0.0\n",
            "hinoCuiaba.txt: 0.00941256448949808\n",
            "hinoFlamengo.txt: 0.06690606288519169\n",
            "hinoFluminense.txt: 0.13636071958696327\n",
            "hinoFortaleza.txt: 0.11373049509712517\n",
            "hinoGoias.txt: 0.014948054713066497\n",
            "hinoInternacional.txt: 0.004184533865584773\n",
            "hinoJuventude.txt: 0.022046048889236804\n",
            "hinoPalmeiras.txt: 0.04000144662257495\n",
            "hinoSantos.txt: 0.025338820524713493\n",
            "hinoSaoPaulo.txt: 0.44237159595981657\n",
            "\n",
            "Documento mais Similar: hinoSaoPaulo.txt\n",
            "Salve o tricolor paulista\n",
            "Amado clube brasileiro\n",
            "Tu és forte, tu és grande\n",
            "Dentre os grandes és o primeiro\n",
            "Tu és forte, tu és grande\n",
            "Dentre os grandes és o primeiro\n",
            "Ó tricolor\n",
            "Clube bem amado\n",
            "As tuas glórias\n",
            "Vêm do passado\n",
            "Ó tricolor\n",
            "Clube bem amado\n",
            "As tuas glórias\n",
            "Vêm do passado\n",
            "São teus guias brasileiros\n",
            "Que te amam ternamente\n",
            "De São Paulo tens o nome\n",
            "Que ostentas dignamente\n",
            "De São Paulo tens o nome\n",
            "Que ostentas dignamente\n",
            "Ó tricolor\n",
            "Clube bem amado\n",
            "As tuas glórias\n",
            "Vêm do passado\n",
            "Ó tricolor\n",
            "Clube bem amado\n",
            "As tuas glórias\n",
            "Vêm do passado\n",
            "\n",
            "\n",
            "Digite a consulta ('!' para terminar): !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parte 3 com steamming"
      ],
      "metadata": {
        "id": "99qRojxluIYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import unidecode\n",
        "import math\n",
        "import numpy\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "\n",
        "def abreArquivo(nomeArquivo):\n",
        "  fp = open(nomeArquivo, 'r')\n",
        "  texto = fp.read()\n",
        "  return texto\n",
        "\n",
        "#abre o arquivo, faz o unidecode, remove pontuação, separa os termos, ordena os termos, remove duplicatas e \n",
        "#retorna a lista de termos\n",
        "def separaArquivo(nomeArquivo):\n",
        "  texto = abreArquivo(nomeArquivo)\n",
        "  termos = separaString(texto)\n",
        "  termos.sort()\n",
        "  termos = list(dict.fromkeys(termos))\n",
        "\n",
        "  return termos\n",
        "\n",
        "#abre o arquivo, faz o unidecode, remove pontuação, separa os termos, ordena os termos, mas não remove duplicatas\n",
        "def listaArquivo(nomeArquivo):\n",
        "  texto = abreArquivo(nomeArquivo)\n",
        "  termos = separaString(texto)\n",
        "\n",
        "  return termos\n",
        "\n",
        "#stopwords tratadas\n",
        "def getStopwords():\n",
        "  nltk.download('stopwords')\n",
        "  stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "  stopwordsUni = []\n",
        "  for i in stopwords:\n",
        "    stopwordsUni.append(unidecode.unidecode(i))\n",
        "  stopwordsUni = list(dict.fromkeys(stopwordsUni))\n",
        "\n",
        "  return stopwordsUni\n",
        "\n",
        "\n",
        "#variaveis globais utiliadas no separaString\n",
        "stopwords = getStopwords()\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def separaString(texto):\n",
        "  texto = unidecode.unidecode(texto)\n",
        "  pontuacao = string.punctuation\n",
        "  for i in pontuacao:\n",
        "    texto = texto.replace(i,\"\")\n",
        "  \n",
        "  texto = re.sub(r'\\d+', '', texto)\n",
        "  termos = texto.lower().split()\n",
        "\n",
        "  for i in stopwords:\n",
        "    while i in termos:\n",
        "      termos.remove(i)\n",
        "\n",
        "  termosRad = []\n",
        "  for i in range(len(termos)):\n",
        "    termosRad.append(stemmer.stem(termos[i]))\n",
        "\n",
        "  return termosRad\n",
        "\n",
        "def normalizaConsulta(vocabulario, consulta):\n",
        "  termosConsulta = separaString(consulta)\n",
        "  termos = []\n",
        "  for i in termosConsulta:\n",
        "    if i in vocabulario:\n",
        "      termos.append(i)\n",
        "\n",
        "  return termos\n",
        "\n",
        "  \n",
        "def comparaTermos(vocabulario, documento):\n",
        "  bagOfWords = []\n",
        "  for i in vocabulario:\n",
        "    if i in documento:\n",
        "      bagOfWords.append(1)\n",
        "    else:\n",
        "      bagOfWords.append(0)\n",
        "\n",
        "  return bagOfWords\n",
        "\n",
        "def frequenciaTermos(vocabulario, documento):\n",
        "  bagOfWords = []\n",
        "  for i in vocabulario:\n",
        "    for j in documento:\n",
        "      if j in vocabulario:\n",
        "        contador = documento.count(i)\n",
        "        bagOfWords.append(contador)\n",
        "        break\n",
        "      else:\n",
        "        bagOfWords.append(0)\n",
        "        break\n",
        "\n",
        "  return bagOfWords\n",
        "\n",
        "def calculaTF(bagOfWords):\n",
        "  tf = []\n",
        "  log = 0\n",
        "  for i in bagOfWords:\n",
        "    num = int(i)\n",
        "    if num!=0:\n",
        "      log = math.log(num, 2)\n",
        "      tf.append(round(1+log, 3))\n",
        "    else:\n",
        "      tf.append(0)\n",
        "\n",
        "  return tf\n",
        "\n",
        "def calculaIDF(lista):\n",
        "  vocabulario = geraVocabulario(lista)\n",
        "  idf = []\n",
        "  for i in vocabulario:\n",
        "      contador = 0\n",
        "      for j in lista:\n",
        "          documento = separaArquivo(j)\n",
        "          if i in documento:\n",
        "              contador = contador + 1\n",
        "      idf.append(contador)\n",
        "  idf = [round(math.log(len(lista)/i, 2),3) for i in idf]\n",
        "\n",
        "  return idf\n",
        "\n",
        "def calculaTFIDFLista(vocabulario, lista):\n",
        "  idf = calculaIDF(lista)\n",
        "  listaTFIDF = []\n",
        "  for i in lista:\n",
        "    tfidf = []\n",
        "    documento = listaArquivo(i)\n",
        "    bagOfWords = frequenciaTermos(vocabulario, documento)\n",
        "    tf = calculaTF(bagOfWords)\n",
        "    tfidf = [round(tf[j]*idf[j], 3) for j in range(len(tf))]\n",
        "    listaTFIDF.append(tfidf)\n",
        "  \n",
        "  return listaTFIDF\n",
        "\n",
        "def calculaTFIDFConsulta(vocabulario, lista, consulta):\n",
        "  termosConsulta = normalizaConsulta(vocabulario, consulta)\n",
        "  bag = frequenciaTermos(vocabulario, termosConsulta)\n",
        "  idf = calculaIDF(lista)\n",
        "  tf = calculaTF(bag)\n",
        "  tfidf = [round(tf[j]*idf[j], 3) for j in range(len(tf))]\n",
        "\n",
        "  return tfidf\n",
        "  \n",
        "\n",
        "def mostraDadosListaArquivos(vocabulario, lista):\n",
        "  for i in lista:\n",
        "    bagOfWords = []\n",
        "    documento = listaArquivo(i)\n",
        "    print(f'\\nDocumento: {documento}')\n",
        "    bagOfWords = frequenciaTermos(vocabulario, documento)\n",
        "    print(f'Bag of Words: {bagOfWords}')\n",
        "    tf = calculaTF(bagOfWords)\n",
        "    print(f'TF: {tf}')\n",
        "\n",
        "\n",
        "def geraVocabulario(lista):\n",
        "    vocabulario = []\n",
        "    for i in lista:\n",
        "        documento = separaArquivo(i)\n",
        "        vocabulario = vocabulario + documento\n",
        "    vocabulario = list(dict.fromkeys(vocabulario))\n",
        "    vocabulario.sort()\n",
        "\n",
        "    return vocabulario\n",
        "\n",
        "def escreveVocabulario(lista):\n",
        "    vocabulario = geraVocabulario(lista)\n",
        "    fp = open('vocabulario.txt', 'w')\n",
        "    for i in vocabulario:\n",
        "        fp.write(i + '\\n')\n",
        "\n",
        "def calculaSimilaridade(vetorA, vetorB):\n",
        "  produtoInterno = 0\n",
        "  for i in range (len(vetorA)):\n",
        "    temp = vetorA[i]*vetorB[i]\n",
        "    produtoInterno = produtoInterno + temp\n",
        "\n",
        "  normaVetorA = numpy.linalg.norm(vetorA)\n",
        "  normaVetorB = numpy.linalg.norm(vetorB)\n",
        "  produtoNorma = normaVetorA*normaVetorB\n",
        "  if produtoNorma!=0:\n",
        "    similaridade = produtoInterno/produtoNorma\n",
        "  else:\n",
        "    similaridade = 0\n",
        "\n",
        "  return similaridade\n",
        "\n",
        "def calculaSimilaridadeLista(tfidf, vetorConsulta):\n",
        "  vetorSimilaridades = []\n",
        "  for i in range(len(tfidf)):\n",
        "    vetorSimilaridades.append(calculaSimilaridade(tfidf[i], vetorConsulta))\n",
        "\n",
        "  return vetorSimilaridades\n",
        "\n",
        "def mostraVetor(vetor):\n",
        "  print('\\n'.join('{}: {}'.format(*k) for k in enumerate(vetor, 1)))\n",
        "\n",
        "def mostraNomeVetor(vetor, lista):\n",
        "  for i in range(len(vetor)):\n",
        "    print(f'{lista[i]}: {vetor[i]}')\n",
        "\n",
        "def mostraDocSimilar(vetorSimilaridade, lista):\n",
        "  maiorSim = max(vetorSimilaridade)\n",
        "\n",
        "  if maiorSim == 0:\n",
        "    print(f'\\nNao existe documento similar na colecao')\n",
        "    return\n",
        "\n",
        "  posDoc = vetorSimilaridade.index(maiorSim)\n",
        "  print(f'\\nDocumento mais Similar: {lista[posDoc]}')\n",
        "  print(abreArquivo(lista[posDoc]))\n",
        "\n",
        "def inputCalculaConsulta(vocabulario, lista, tfidf):\n",
        "  while(1):\n",
        "    consulta = input(\"\\nDigite a consulta ('!' para terminar): \")\n",
        "    if consulta == '!':\n",
        "      break\n",
        "\n",
        "    vetorConsulta = calculaTFIDFConsulta(vocabulario, lista, consulta)\n",
        "\n",
        "    vetorSimilaridade = calculaSimilaridadeLista(tfidf, vetorConsulta)\n",
        "\n",
        "    print('\\nGrau de Similaridade')\n",
        "    mostraNomeVetor(vetorSimilaridade, lista)\n",
        "\n",
        "    mostraDocSimilar(vetorSimilaridade, lista)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "listaDoc = [ 'hinoAmericaMG.txt', 'hinoAthletico.txt', 'hinoAtleticoGO.txt', 'hinoAtleticoMG.txt', 'hinoAvai.txt',\n",
        "          'hinoBotafogo.txt', 'hinoBragantino.txt', 'hinoCeara.txt', 'hinoCorinthians.txt', 'hinoCoritiba.txt',\n",
        "          'hinoCuiaba.txt', 'hinoFlamengo.txt', 'hinoFluminense.txt', 'hinoFortaleza.txt', 'hinoGoias.txt',\n",
        "          'hinoInternacional.txt', 'hinoJuventude.txt','hinoPalmeiras.txt', 'hinoSantos.txt', 'hinoSaoPaulo.txt'] \n",
        "vocabulario = geraVocabulario(listaDoc)\n",
        "\n",
        "tfidf = calculaTFIDFLista(vocabulario, listaDoc)\n",
        "inputCalculaConsulta(vocabulario, listaDoc, tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ss26Zxzvahh",
        "outputId": "f6ad9167-5735-4dc1-eccd-e29c860f8faf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Digite a consulta ('!' para terminar): salve o tricolor  paulista amado clube brasileiro\n",
            "\n",
            "Grau de Similaridade\n",
            "hinoAmericaMG.txt: 0.0\n",
            "hinoAthletico.txt: 0.0\n",
            "hinoAtleticoGO.txt: 0.0\n",
            "hinoAtleticoMG.txt: 0.019427766446752464\n",
            "hinoAvai.txt: 0.0\n",
            "hinoBotafogo.txt: 0.0\n",
            "hinoBragantino.txt: 0.0\n",
            "hinoCeara.txt: 0.0\n",
            "hinoCorinthians.txt: 0.0994213614353375\n",
            "hinoCoritiba.txt: 0.02703400052369766\n",
            "hinoCuiaba.txt: 0.009644403967708283\n",
            "hinoFlamengo.txt: 0.0688057522242013\n",
            "hinoFluminense.txt: 0.13957246843072185\n",
            "hinoFortaleza.txt: 0.11671283947014237\n",
            "hinoGoias.txt: 0.015369710385788495\n",
            "hinoInternacional.txt: 0.004340386047125665\n",
            "hinoJuventude.txt: 0.023419556316695535\n",
            "hinoPalmeiras.txt: 0.029704386173678293\n",
            "hinoSantos.txt: 0.02634669891878538\n",
            "hinoSaoPaulo.txt: 0.47855612522345864\n",
            "\n",
            "Documento mais Similar: hinoSaoPaulo.txt\n",
            "Salve o tricolor paulista\n",
            "Amado clube brasileiro\n",
            "Tu és forte, tu és grande\n",
            "Dentre os grandes és o primeiro\n",
            "Tu és forte, tu és grande\n",
            "Dentre os grandes és o primeiro\n",
            "Ó tricolor\n",
            "Clube bem amado\n",
            "As tuas glórias\n",
            "Vêm do passado\n",
            "Ó tricolor\n",
            "Clube bem amado\n",
            "As tuas glórias\n",
            "Vêm do passado\n",
            "São teus guias brasileiros\n",
            "Que te amam ternamente\n",
            "De São Paulo tens o nome\n",
            "Que ostentas dignamente\n",
            "De São Paulo tens o nome\n",
            "Que ostentas dignamente\n",
            "Ó tricolor\n",
            "Clube bem amado\n",
            "As tuas glórias\n",
            "Vêm do passado\n",
            "Ó tricolor\n",
            "Clube bem amado\n",
            "As tuas glórias\n",
            "Vêm do passado\n",
            "\n",
            "\n",
            "Digite a consulta ('!' para terminar): !\n"
          ]
        }
      ]
    }
  ]
}